{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ = \"Scalograms-stacked-wavdec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing images for model training --- image size = 256 x 256\n",
    "train_batch = 64\n",
    "test_batch = 64\n",
    "train_set= image_dataset_from_directory(path_,\n",
    "                                labels='inferred',\n",
    "                                label_mode='binary',\n",
    "                                batch_size=train_batch,\n",
    "                                seed=RANDOM_SEED,\n",
    "                                shuffle=True,\n",
    "                                validation_split=0.2,\n",
    "                                subset='training')\n",
    "                                \n",
    "val_set =  image_dataset_from_directory(path_,\n",
    "                                labels='inferred',\n",
    "                                label_mode='binary',\n",
    "                                batch_size=test_batch,\n",
    "                                seed=RANDOM_SEED,\n",
    "                                shuffle=True,\n",
    "                                validation_split=0.2,\n",
    "                                subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds_size = int(int(val_set.__len__())*0.5) # test-test set has 478 images and val set has 1647 images == # 9563 * 0.05\n",
    "test_test_set = val_set.take(test_ds_size)\n",
    "test_set = val_set.skip(test_ds_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_set.__len__(), train_set.__len__(), test_set.__len__(), test_test_set.__len__(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "#from keras.optimizers import gradient_descent_v2 \n",
    "from keras import regularizers, initializers\n",
    "from livelossplot import PlotLossesKeras\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception = InceptionV3(include_top=False, weights='imagenet', input_shape=(256,256,3))\n",
    "output = inception.layers[-1].output\n",
    "output = Flatten()(output)\n",
    "inception = Model(inception.input, output)\n",
    "for layer in inception.layers:\n",
    "    layer.trainable = False\n",
    "inception.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Sequential()\n",
    "\n",
    "model_1.add(inception)\n",
    "model_1.add(Dense(64,activation='relu', input_dim=(256,256,3),  kernel_initializer=initializers.HeNormal(), kernel_regularizer=regularizers.L2(0.5)))\n",
    "model_1.add(Dense(64,activation='relu', kernel_regularizer=regularizers.L2(0.5)))\n",
    "model_1.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model_1.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy','Recall','Precision','AUC'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"Models/music-scalograms-TL-inception-checkpoints/\"\n",
    "filepath = root_path + 'music-scalograms-TL-l2-5-inception-model-t1.h5'\n",
    "\n",
    "k=2\n",
    "if not os.path.exists(root_path): os.makedirs(root_path)\n",
    "else: \n",
    "    while(os.path.exists(filepath)): \n",
    "        filepath = filepath[:-4] + str(k) + '.h5' \n",
    "        k = k+1\n",
    "\n",
    "callbacks = [#EarlyStopping(monitor='val_accuracy', patience=4),\n",
    "            ModelCheckpoint(filepath=filepath, monitor=\"val_accuracy\", mode='max', save_best_only=True),\n",
    "            PlotLossesKeras()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = model_1.fit(train_set,\n",
    "                epochs=25,\n",
    "                #steps_per_epoch=64,\n",
    "                validation_data=test_set,\n",
    "                #validation_steps=32,\n",
    "                callbacks=callbacks\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame.from_dict(h.history).to_csv(filepath[:-2] + 'csv' , index=False)\n",
    "#data=pd.read_csv(\"Models/scalogram-base-model-checkpoints/scalogram-base-model-1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.evaluate(test_test_set)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
